{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from config import gkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>DateType</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Race</th>\n",
       "      <th>ResidenceCity</th>\n",
       "      <th>ResidenceCounty</th>\n",
       "      <th>ResidenceState</th>\n",
       "      <th>...</th>\n",
       "      <th>Benzodiazepine</th>\n",
       "      <th>Methadone</th>\n",
       "      <th>Amphetamine</th>\n",
       "      <th>Tramadol</th>\n",
       "      <th>Morphine Not Heroin</th>\n",
       "      <th>Hydromorphone</th>\n",
       "      <th>Other</th>\n",
       "      <th>OpiateNOS</th>\n",
       "      <th>Any Opioid</th>\n",
       "      <th>MannerofDeath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13-0102</td>\n",
       "      <td>03/21/2013 12:00:00 AM</td>\n",
       "      <td>DateofDeath</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>NORWALK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Accident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>16-0165</td>\n",
       "      <td>03/13/2016 12:00:00 AM</td>\n",
       "      <td>DateofDeath</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>SANDY HOOK</td>\n",
       "      <td>FAIRFIELD</td>\n",
       "      <td>CT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>Accident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>16-0208</td>\n",
       "      <td>03/31/2016 12:00:00 AM</td>\n",
       "      <td>DateofDeath</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>RYE</td>\n",
       "      <td>WESTCHESTER</td>\n",
       "      <td>NY</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>Accident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>13-0052</td>\n",
       "      <td>02/13/2013 12:00:00 AM</td>\n",
       "      <td>DateofDeath</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Asian, Other</td>\n",
       "      <td>FLUSHING</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Accident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>14-0277</td>\n",
       "      <td>06/29/2014 12:00:00 AM</td>\n",
       "      <td>DateofDeath</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>BRISTOL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Accident</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       ID                    Date     DateType   Age     Sex  \\\n",
       "0           1  13-0102  03/21/2013 12:00:00 AM  DateofDeath  48.0    Male   \n",
       "1           2  16-0165  03/13/2016 12:00:00 AM  DateofDeath  30.0  Female   \n",
       "2           3  16-0208  03/31/2016 12:00:00 AM  DateofDeath  23.0    Male   \n",
       "3           4  13-0052  02/13/2013 12:00:00 AM  DateofDeath  22.0    Male   \n",
       "4           5  14-0277  06/29/2014 12:00:00 AM  DateofDeath  23.0    Male   \n",
       "\n",
       "           Race ResidenceCity ResidenceCounty ResidenceState  ...  \\\n",
       "0         Black       NORWALK             NaN            NaN  ...   \n",
       "1         White    SANDY HOOK       FAIRFIELD             CT  ...   \n",
       "2         White           RYE     WESTCHESTER             NY  ...   \n",
       "3  Asian, Other      FLUSHING          QUEENS            NaN  ...   \n",
       "4         White       BRISTOL             NaN            NaN  ...   \n",
       "\n",
       "  Benzodiazepine Methadone Amphetamine Tramadol Morphine Not Heroin  \\\n",
       "0            NaN       NaN         NaN      NaN                 NaN   \n",
       "1            NaN       NaN         NaN      NaN                 NaN   \n",
       "2            NaN       NaN         NaN      NaN                 NaN   \n",
       "3            NaN       NaN         NaN      NaN                 NaN   \n",
       "4            NaN       NaN         NaN      NaN                 NaN   \n",
       "\n",
       "  Hydromorphone Other OpiateNOS Any Opioid MannerofDeath  \n",
       "0           NaN   NaN       NaN        NaN      Accident  \n",
       "1           NaN   NaN       NaN          Y      Accident  \n",
       "2           NaN   NaN       NaN          Y      Accident  \n",
       "3           NaN   NaN       NaN        NaN      Accident  \n",
       "4           NaN   NaN       NaN        NaN      Accident  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe from cleaned data\n",
    "clean_data = pd.read_csv(\"Resources/drug_death_data_clean.csv\")\n",
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data by Death City by count\n",
    "city_grouped = clean_data.groupby(\"DeathCity\")\n",
    "city_counts = pd.DataFrame(city_grouped.count()[\"ID\"])\n",
    "city_counts = city_counts.reset_index()\n",
    "city_counts = city_counts.rename(columns={\"DeathCity\":\"City\",\"ID\":\"Deaths\"})\n",
    "# Drop city 06340\n",
    "city_counts = city_counts.loc[city_counts[\"City\"] != \"06340\",:]\n",
    "\n",
    "#city_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing AMSTON...\n",
      "Processing ANDOVER...\n",
      "Processing ANSONIA...\n",
      "Processing ASHFORD...\n",
      "Processing AVON...\n",
      "Processing BAKERSVILLE...\n",
      "Processing BALTIC...\n",
      "Processing BANTAM...\n",
      "Processing BARKHAMSTED...\n",
      "Processing BEACON FALLS...\n",
      "Processing BERLIN...\n",
      "Processing BETHANY...\n",
      "Processing BETHEL...\n",
      "Processing BETHLEHEM...\n",
      "Processing BLOOMFIELD...\n",
      "Processing BOLTON...\n",
      "Processing BOZRAH...\n",
      "Processing BRANFORD...\n",
      "Processing BRIDGEPORT...\n",
      "Processing BRIDGEWATER...\n",
      "Processing BRISTOL...\n",
      "Processing BROAD BROOK...\n",
      "Processing BROOKFIELD...\n",
      "Processing BROOKLYN...\n",
      "Processing BURLINGTON...\n",
      "Processing CANTERBURY...\n",
      "Processing CANTON...\n",
      "Processing CENTRAL VILLAGE...\n",
      "Processing CHAPLIN...\n",
      "Processing CHESHIRE...\n",
      "Processing CHESTER...\n",
      "Processing CLINTON...\n",
      "Processing COLCHESTER...\n",
      "Processing COLUMBIA...\n",
      "Processing CORNWALL BRIDGE...\n",
      "Processing COS COB...\n",
      "Processing COVENTRY...\n",
      "Processing CROMWELL...\n",
      "Processing DANBURY...\n",
      "Processing DANIELSON...\n",
      "Processing DARIEN...\n",
      "Processing DAYVILLE...\n",
      "Processing DEEP RIVER...\n",
      "Processing DERBY...\n",
      "Processing DURHAM...\n",
      "Processing EAST CANAAN...\n",
      "Processing EAST GRANBY...\n",
      "Processing EAST HADDAM...\n",
      "Processing EAST HAMPTON...\n",
      "Processing EAST HARTFORD...\n",
      "Processing EAST HARTLAND...\n",
      "Processing EAST HAVEN...\n",
      "Processing EAST LYME...\n",
      "Processing EAST WINDSOR...\n",
      "Processing EAST WOODSTOCK...\n",
      "Processing EASTFORD...\n",
      "Processing EASTON...\n",
      "Processing ELLINGTON...\n",
      "Processing ENFIELD...\n",
      "Processing ESSEX...\n",
      "Processing FAIRFIELD...\n",
      "Processing FARMINGTON...\n",
      "Processing FRANKLIN...\n",
      "Processing GALES FERRY...\n",
      "Processing GLASTONBURY...\n",
      "Processing GOSHEN...\n",
      "Processing GRANBY...\n",
      "Processing GREENWICH...\n",
      "Processing GRISWOLD...\n",
      "Processing GROTON...\n",
      "Processing GROTON LONG POINT...\n",
      "Processing GUILFORD...\n",
      "Processing HADDAM...\n",
      "Processing HAMDEN...\n",
      "Processing HAMPTON...\n",
      "Processing HANOVER...\n",
      "Processing HARTFORD...\n",
      "Processing HARWINTON...\n",
      "Processing HEBRON...\n",
      "Processing HIGGANUM...\n",
      "Processing IVORYTON...\n",
      "Processing JEWETT CITY...\n",
      "Processing KENT...\n",
      "Processing KILLINGLY...\n",
      "Processing KILLINGWORTH...\n",
      "Processing LEBANON...\n",
      "Processing LEDYARD...\n",
      "Processing LISBON...\n",
      "Processing LITCHFIELD...\n",
      "Processing MADISON...\n",
      "Processing MANCHESTER...\n",
      "Processing MANSFIELD...\n",
      "Processing MARLBOROUGH...\n",
      "Processing MASHANTUCKET...\n",
      "Processing MERIDEN...\n",
      "Processing MIDDLEBURY...\n",
      "Processing MIDDLEFIELD...\n",
      "Processing MIDDLETOWN...\n",
      "Processing MILFORD...\n",
      "Processing MONROE...\n",
      "Processing MONTVILLE...\n",
      "Processing MOODUS...\n",
      "Processing MOOSUP...\n",
      "Processing MORRIS...\n",
      "Processing MYSTIC...\n",
      "Processing N HAVEN...\n",
      "Processing NAUGATUCK...\n",
      "Processing NEW BRITAIN...\n",
      "Processing NEW CANAAN...\n",
      "Processing NEW FAIRFIELD...\n",
      "Processing NEW HARTFORD...\n",
      "Processing NEW HAVEN...\n",
      "Processing NEW LONDON...\n",
      "Processing NEW MILFORD...\n",
      "Processing NEW PRESTON...\n",
      "Processing NEWINGTON...\n",
      "Processing NEWTOWN...\n",
      "Processing NIANTIC...\n",
      "Processing NO HAVEN...\n",
      "Processing NORFOLK...\n",
      "Processing NORTH BRANFORD...\n",
      "Processing NORTH CANAAN...\n",
      "Processing NORTH GRANBY...\n",
      "Processing NORTH GROSVENORDALE...\n",
      "Processing NORTH HAVEN...\n",
      "Processing NORTH STONINGTON...\n",
      "Processing NORTH WINDAM...\n",
      "Processing NORTH WINDHAM...\n",
      "Processing NORTHFORD...\n",
      "Processing NORWALK...\n",
      "Processing NORWICH...\n",
      "Processing OAKDALE...\n",
      "Processing OAKVILLE...\n",
      "Processing OLD LYME...\n",
      "Processing OLD SAYBROOK...\n",
      "Processing ONECO...\n",
      "Processing ORANGE...\n",
      "Processing OXFORD...\n",
      "Processing PAWCATUCK...\n",
      "Processing PLAINFIELD...\n",
      "Processing PLAINVILLE...\n",
      "Processing PLANTSVILLE...\n",
      "Processing PLYMOUTH...\n",
      "Processing POMFRET...\n",
      "Processing PORTLAND...\n",
      "Processing PRESTON...\n",
      "Processing PROSPECT...\n",
      "Processing PUTNAM...\n",
      "Processing QUAKER HILL...\n",
      "Processing QUINEBAUG...\n",
      "Processing REDDING...\n",
      "Processing RIDGEFIELD...\n",
      "Processing ROCKVILLE...\n",
      "Processing ROCKY HILL...\n",
      "Processing ROGERS...\n",
      "Processing S GLASTONBURY...\n",
      "Processing SALEM...\n",
      "Processing SALISBURY...\n",
      "Processing SANDY HOOK...\n",
      "Processing SEYMOUR...\n",
      "Processing SHARON...\n",
      "Processing SHELTON...\n",
      "Processing SHERMAN...\n",
      "Processing SIMSBURY...\n",
      "Processing SOMERS...\n",
      "Processing SOUTH WINDSOR...\n",
      "Processing SOUTHBURY...\n",
      "Processing SOUTHINGTON...\n",
      "Processing SPRAGUE...\n",
      "Processing STAFFORD...\n",
      "Processing STAFFORD SPGS...\n",
      "Processing STAFFORD SPRINGS...\n",
      "Processing STAMFORD...\n",
      "Processing STERLING...\n",
      "Processing STONINGTON...\n",
      "Processing STORRS...\n",
      "Processing STRATFORD...\n",
      "Processing SUFFIELD...\n",
      "Processing TAFTVILLE...\n",
      "Processing TARIFFVILLE...\n",
      "Processing TERRYVILLE...\n",
      "Processing THOMASTON...\n",
      "Processing THOMPSON...\n",
      "Processing TOLLAND...\n",
      "Processing TORRINGTON...\n",
      "Processing TRUMBULL...\n",
      "Processing UNCASVILLE...\n",
      "Processing UNIONVILLE...\n",
      "Processing VERNON...\n",
      "Processing VERNON-ROCKVILLE...\n",
      "Processing VOLUNTOWN...\n",
      "Processing W HAVEN...\n",
      "Processing WALLINGFORD...\n",
      "Processing WARREN...\n",
      "Processing WASHINGTON...\n",
      "Processing WATERBURY...\n",
      "Processing WATERFORD...\n",
      "Processing WATERTOWN...\n",
      "Processing WAUREGAN...\n",
      "Processing WEATOGUE...\n",
      "Processing WEST HARTFORD...\n",
      "Processing WEST HAVEN...\n",
      "Processing WEST STAFFORD...\n",
      "Processing WEST SUFFIELD...\n",
      "Processing WESTBROOK...\n",
      "Processing WESTON...\n",
      "Processing WESTPORT...\n",
      "Processing WETHERSFIELD...\n",
      "Processing WILLIMANTIC...\n",
      "Processing WILLINGTON...\n",
      "Processing WILTON...\n",
      "Processing WINCHESTER...\n",
      "Processing WINDHAM...\n",
      "Processing WINDSOR...\n",
      "Processing WINDSOR LOCKS...\n",
      "Processing WINSTED...\n",
      "Processing WOLCOTT...\n",
      "Processing WOODBRIDGE...\n",
      "Processing WOODBURY...\n",
      "Processing WOODSTOCK...\n",
      "Latitude/Longitude processing complete!\n"
     ]
    }
   ],
   "source": [
    "# Create new columns for city coordinates\n",
    "city_counts[\"Latitude\"] = \"\"\n",
    "city_counts[\"Longitude\"] = \"\"\n",
    "\n",
    "\n",
    "# Call google places api for each city and retrieve coordinates\n",
    "base_url = \"https://maps.googleapis.com/maps/api/place/findplacefromtext/json?\"\n",
    "params = {\"key\":gkey,\n",
    "         \"input\":\"\",\n",
    "         \"inputtype\":\"textquery\",\n",
    "         \"fields\":\"geometry/location\"}\n",
    "\n",
    "for index, row in city_counts.iterrows():\n",
    "    # Change input for each row/city.  Add \"CT\" since we're working in Connecticut\n",
    "    params[\"input\"] = row[\"City\"] + \",CT\"\n",
    "    # Call google places API\n",
    "    response = requests.get(base_url,params)\n",
    "    print(f\"Processing {row['City']}...\")\n",
    "    # If good response, store lat and lng in df\n",
    "    if response.status_code == 200:\n",
    "        try:\n",
    "            city_counts.loc[index,\"Latitude\"] = response.json()['candidates'][0][\"geometry\"][\"location\"][\"lat\"]\n",
    "            city_counts.loc[index,\"Longitude\"] = response.json()['candidates'][0][\"geometry\"][\"location\"][\"lng\"]\n",
    "        except IndexError:\n",
    "          print(f\"Information not found for {row['City']}! Continuing...\")\n",
    "    else:\n",
    "        print(f\"Information not found for {row['City']}! Continuing...\")\n",
    "              \n",
    "print(\"Latitude/Longitude processing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMSTON</td>\n",
       "      <td>1</td>\n",
       "      <td>41.6254</td>\n",
       "      <td>-72.3431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANDOVER</td>\n",
       "      <td>3</td>\n",
       "      <td>41.7373</td>\n",
       "      <td>-72.3704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANSONIA</td>\n",
       "      <td>23</td>\n",
       "      <td>41.3462</td>\n",
       "      <td>-73.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASHFORD</td>\n",
       "      <td>6</td>\n",
       "      <td>41.8731</td>\n",
       "      <td>-72.1216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AVON</td>\n",
       "      <td>5</td>\n",
       "      <td>41.8096</td>\n",
       "      <td>-72.8305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>WINSTED</td>\n",
       "      <td>12</td>\n",
       "      <td>41.9212</td>\n",
       "      <td>-73.0601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>WOLCOTT</td>\n",
       "      <td>2</td>\n",
       "      <td>41.6023</td>\n",
       "      <td>-72.9868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>WOODBRIDGE</td>\n",
       "      <td>4</td>\n",
       "      <td>41.3526</td>\n",
       "      <td>-73.0084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>WOODBURY</td>\n",
       "      <td>3</td>\n",
       "      <td>41.5445</td>\n",
       "      <td>-73.209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>WOODSTOCK</td>\n",
       "      <td>4</td>\n",
       "      <td>41.9484</td>\n",
       "      <td>-71.974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           City  Deaths Latitude Longitude\n",
       "1        AMSTON       1  41.6254  -72.3431\n",
       "2       ANDOVER       3  41.7373  -72.3704\n",
       "3       ANSONIA      23  41.3462   -73.079\n",
       "4       ASHFORD       6  41.8731  -72.1216\n",
       "5          AVON       5  41.8096  -72.8305\n",
       "..          ...     ...      ...       ...\n",
       "216     WINSTED      12  41.9212  -73.0601\n",
       "217     WOLCOTT       2  41.6023  -72.9868\n",
       "218  WOODBRIDGE       4  41.3526  -73.0084\n",
       "219    WOODBURY       3  41.5445   -73.209\n",
       "220   WOODSTOCK       4  41.9484   -71.974\n",
       "\n",
       "[220 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify lat/lng has been added.\n",
    "city_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deaths</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>County</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FAIRFIELD</th>\n",
       "      <td>597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HARTFORD</th>\n",
       "      <td>1187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LITCHFIELD</th>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MIDDLESEX</th>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEW HAVEN</th>\n",
       "      <td>1068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEW LONDON</th>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOLLAND</th>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WINDHAM</th>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Deaths\n",
       "County            \n",
       "FAIRFIELD      597\n",
       "HARTFORD      1187\n",
       "LITCHFIELD     235\n",
       "MIDDLESEX      177\n",
       "NEW HAVEN     1068\n",
       "NEW LONDON     357\n",
       "TOLLAND        109\n",
       "WINDHAM        134"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group data by Death County by count\n",
    "#clean_data.loc[clean_data[\"DeathCounty\"]==\"USA\",:]\n",
    "# One of the counties is \"USA\"; it's city is HARTFORD.  Change county to HARTFORD\n",
    "clean_data[\"DeathCounty\"] = clean_data[\"DeathCounty\"].replace({\"USA\":\"HARTFORD\"})\n",
    "# Clean any/all whitespaces around county names\n",
    "clean_data[\"DeathCounty\"] = clean_data[\"DeathCounty\"].str.strip()\n",
    "\n",
    "# Now that the data is cleaner, group it\n",
    "county_grouped = clean_data.groupby(\"DeathCounty\")\n",
    "county_counts = pd.DataFrame(county_grouped.count()[\"ID\"])\n",
    "county_counts = county_counts.rename_axis('County')\n",
    "county_counts = county_counts.rename(columns={\"ID\":\"Deaths\"})\n",
    "\n",
    "county_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Want to center the map on CT, so we need coordinates for the \"center\" of CT.\n",
    "ct_coord = (41.5032, -72.6877)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure gmaps\n",
    "import gmaps\n",
    "gmaps.configure(api_key=gkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load geojson_geometries for US Counties\n",
    "import gmaps.geojson_geometries\n",
    "county_geojson = gmaps.geojson_geometries.load_geometry('us-counties')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Windham',\n",
       " 'Tolland',\n",
       " 'Hartford',\n",
       " 'Middlesex',\n",
       " 'Litchfield',\n",
       " 'Fairfield',\n",
       " 'New London',\n",
       " 'New Haven']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create geo_json of just CT\n",
    "ct_geojson = {'type':'FeatureCollection',\n",
    "             'features':[]}\n",
    "\n",
    "for county in county_geojson['features']:\n",
    "    if county['properties'][\"STATE\"] == '09':\n",
    "        ct_geojson['features'].append(county)\n",
    "\n",
    "# Print list of counties for order\n",
    "counties_ordered = []\n",
    "for county in ct_geojson['features']:\n",
    "    counties_ordered.append(county['properties']['NAME'])\n",
    "\n",
    "counties_ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To convert deaths/weights to color, I'm modifying a color normalizer from the geojson documentation:\n",
    "# https://jupyter-gmaps.readthedocs.io/en/latest/tutorial.html#geojson-layer\n",
    "# Requires a min and max value which I've manually pulled from the county data:\n",
    "min_deaths = 100\n",
    "max_deaths = 1000 # Setting max intensity to 400 for better vis\n",
    "death_range = max_deaths - min_deaths\n",
    "# Import neccessary functionality:\n",
    "from matplotlib.cm import inferno\n",
    "from matplotlib.colors import to_hex\n",
    "\n",
    "def calculate_color(weight):\n",
    "    \"\"\"\n",
    "    Convert the weight to a color\n",
    "    \"\"\"\n",
    "    # make weight a number between 0 and 1\n",
    "    normalized_deaths = (weight - min_deaths) / death_range\n",
    "\n",
    "    # invert deaths so that high inequality gives dark color\n",
    "    inverse_deaths = 1.0 - normalized_deaths\n",
    "\n",
    "    # transform the deaths/weights to a matplotlib color\n",
    "    mpl_color = inferno(inverse_deaths)\n",
    "\n",
    "    # transform from a matplotlib color to a valid CSS color\n",
    "    gmaps_color = to_hex(mpl_color, keep_alpha=False)\n",
    "\n",
    "    return gmaps_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#f2f482',\n",
       " '#f9fc9d',\n",
       " '#000004',\n",
       " '#f4df53',\n",
       " '#fbbe23',\n",
       " '#a62d60',\n",
       " '#f57d15',\n",
       " '#000004']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add column with color values\n",
    "county_counts['Color'] = ''\n",
    "for county,deaths in county_counts.iterrows():\n",
    "    color = calculate_color(deaths[\"Deaths\"])\n",
    "    county_counts.loc[county,'Color'] = color\n",
    "    \n",
    "# Add colors to list in correct order\n",
    "colors = []\n",
    "for county in counties_ordered:\n",
    "    colors.append(county_counts.loc[county.upper(),'Color'])\n",
    "    \n",
    "colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfe61ed80d064dcca3da7990effe1196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(layout=FigureLayout(height='420px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Deaths by County Map\n",
    "#figure_layout_0 = {}\n",
    "county_map = gmaps.figure(center=ct_coord, zoom_level=8.4)\n",
    "geo_layer = gmaps.geojson_layer(ct_geojson,\n",
    "                                fill_color=colors,\n",
    "#                                stroke_color=colors,\n",
    "                                fill_opacity=0.6)\n",
    "county_map.add_layer(geo_layer)\n",
    "\n",
    "county_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64291e701bcf405e90a2b2c391d1f38f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(layout=FigureLayout(height='420px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Deaths by City Map\n",
    "\n",
    "#figure_layout_1 = {backgroundColor:'gray'}\n",
    "city_map = gmaps.figure(center=ct_coord, zoom_level=8.4)\n",
    "heatmap_layer = gmaps.heatmap_layer(\n",
    "    city_counts[[\"Latitude\",\"Longitude\"]],\n",
    "    weights=city_counts[\"Deaths\"],\n",
    "    max_intensity=100,\n",
    "    point_radius=40.0,\n",
    "    gradient=((0,0,0,0.2),'yellow',(255,160,0,0.8),'red')\n",
    "    )\n",
    "city_map.add_layer(heatmap_layer)\n",
    "city_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
